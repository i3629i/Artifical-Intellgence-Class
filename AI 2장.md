# 지능적 에이전트

### 1. 에이전트 란?
* 지각하고 행동하는 개체
* ?를 통해 지각, ? 를 통해 행동

### 2. 에이전트 함수란?
* Input : ? , Output : ?
* 지각 시퀀스란??

### 3. 이성적인 에이전트
* 성능 척도 : 성능을 나타내는 수치 같은 느낌
* 이성적인 에이전트 조건은??

### 4. 작업 환경(Task Environment)
* P -
* E - 
* A - 
* S - 

### 5. 작업 환경 특징
* 완전 관측 vs 부분 관측
* 결정적 vs 확률적
* 정적 vs 동적
* 단편적 vs 순차적
* 단일 에이전트 vs 다중 에이전트
* 이산적 vs 연속적

### 6. 문제 해결 에이전트
state <- Update-State(state, percept(지각))<br>
if seq is empty then do //행동 시퀀스가 비어있으면 실행시킨다. <br>
&nbsp; goal <- 목표-goal(state) // 현재 상태에 대한 목표를 새롭게 정의한다. 목표설정 <br>
&nbsp; problem <- 목표-Problem(state, goal) // 현재 상태에 대한 문제를 표현한다. 문제표현<br>
&nbsp; seq <- Search(problem) // 행동 시퀀스에 문제에 대한 탐색을 실행한 결과를 넣는다. 해결책탐색<br>
&nbsp; if seq = 실패 then reutrn a null action //실패한 결과를 받았으면 아무행동도 취하지 않음 <br>
action <- First(seq) // 가장 처음의 seq를 행동에 넣음. 
seq <- Rest(seq) // 다음 행동 시퀀스를 seq에 삽입
return action // 행동 반환

------------------------------------------------

Q1. 에이전트란? <br>
A1. 주변 환경을 통해서 그에 따라 최적의 해를 찾아 행동을 하는 개체, 지각하고 행동하는 개체

Q2. ? 를통해 지각 ?를 통해 행동<br>
A2. 센서를 톻애 지각 작동기를 통해 행동한다.

Q3. 에이전트 함수란<br>
A3. Input : 지각 시퀀스 Output : 행동

Q4. 지각 시퀀스란?<br>
A4. **모든 센서들로부터 지각되는 전체 내역**

Q5. 이성적인 에이전트의 조건?<br>
A5. 성능척도를 최대화는 식으로 기대되는 행동을 취하는 선택을 해야함

Q6. 작업 환경 Task Environment <br>
A6. 자율주행 택시의 경우 예를들어서
* P - Performance Measure, 안전성, 속도, 편안함
* E - Environment, 도로상태, 다른 차들, 지나다니는 사람들
* A - Actuators, 기어, 브레이크, 액셀
* S - Sensors, 물체접근 인식 센서, 카메라, 속도계, 연로측정기 

Q7. 작업 환경 특징
* 완전 vs 부분 - 모든 상태를 보느냐 안보느냐
* 결정 vs 확률 - 현재 상태에서 수행한 행동을 통해 다음 상태가 완벽히 결정 되는가, 아니면 확률적으로 선택 되는가 
* 단편 vs 순차 - 행동에대해 다음 상태가 영향을 미치는가
* 정적 vs 동적 - 결정을 하는 순간에도 행동이 변하면 동적, 안변하면 정적
* 이산 vs 연속 - 이산 숫자로 정확히 표현, 연속은 시간, 키 등 
* 단일 에이전트 vs 다중 에이전트 - 참여하는 수가 단일이냐 다중이냐

---------------------------------------------------------------------

### 7. 문제 표현하기
1. 초기상태
2. 행동
3. 이행 모델
4. 목표 검사
5. 경로 비용 측정

### 8. 상태공간 이란?
* 상태 공간에서 노드는?, 간선은?

### 9. 비용과 해결책
* 움직임 비용(step cost)
  - c(s, action, s') 은??
* 해결책(solution)
  - 초기 상태에서 목푶 상태로 도달하게 하는 시퀀스 
* 최적 해결책 이란?

### 10. 해결책 탐색
* 탐색 트리에서
  - 루트 : ?
  - 노드 : ?
  - 간선 : ?
* 탐색 과정
  - if 현재 상태 = 목표상태 
  - elif 현재 상태 != 목표상태 {현재 상태 확장} // 경계 노드들 중 하나를 선택하여 확장.
* 트리 탐색 알고리즘, 그래프 탐색 알고리즘
* 우회 경로 회피하는 방법은??

### 11. 탐색 알고리즘 구조 및 성능

### 12. 탐색 알고리즘의 기반 구조
* 상태 - 노드에 대응되는 공간의 상태
* 부모 - 노드의 부모 노드
* 행동 - 이 노드를 생성하기위해 부모가 한 행동
* 경로 비용 - 초기 상태에서 이 노드 까지의 경로비용

### 13. 경계
* 경계란?
* 탐색 전략에 따라 큐, 스택, 우선순위 큐 사용
* 너비우선(큐), 깊이우선(스택), 깊이 제한 우선(스택예상), 반복적 깊이 증가(스택예상)

### 14. 탐사집합
* **반복적인 상태를 수행 할 수 있도록 ?를 이용**

### 15. 문제 해결 성능 측정
* 완전성?
* 최적성?
* 시간복잡도
* 공간복잡도

### 16. 문제 해결 성능 측정(2)
* 상태 공간의 그래프의 크기는 노드의 갯수나 간선의 갯수가 많을 수록 크게된다.
* 무한 그래프는 명시적으로 표기 불가.

### 17. 시간/공간 복답도의 3가지 값으로 표현(무한 그래프의 제약을 위해)
* 분기 지수 - 한 상태의 액션이 가장 많은 갯수 (b)
* 가장 얕은 노드의 목표노드 깊이(d) //d가 깊을 수록 오래걸림
* 경로의 최대 길이 (m) // 최대로 깊게 들어갔을 때 얼마인가, 탐색 트리의 최대 깊이

### 18. 시간 공간
* 시간은?
* 공간은?

--------------------------------------------------------------------

Q8. 문제표현 하기<br>
A8.
* 초기 상태 - 초기의 노드의 상태, 시작상태 In(Arad)
* 행동 - 노드가 취할 수 잇는 액션, 행동 ex. Actions(In(Arad)) = (GO(A), Go(B), Go(C)) 
* 이행 모델 - 행동을 취한뒤의 결과 값 ex. Result(In(Arad), Go(A)) = In(A) 
* 목표 상태 - 현재 상태가 목표로 한 상태인지 확인
* 경로 비용 - 각 경로의 비용을 할당.

Q9. c(s, action, s') 은??<br>
A9. s에서 행동을 취해서 S' 까지 도달하는데 드는 비용

Q10. 최적 해결책 이란?<br>
A10. 경로비용이 가장 적은 최적의 해

Q11. 탐색트리에서 루트, 노드, 간선<br>
A11. 루트는 초기상태, 노드는 상태공간의 상태, 간선은 행동?

Q12. 우회경로를 피하는 방법은?<br>
A12. 폐쇄리스트 집합을 만들어 이미 지나간 곳의 경로를 따로 저장해두어 확장중의 신규노드중 폐쇄리스트에 잇는 상태일시 폐기를 한다.

Q13. 경계란 frontier?<br>
A13. 확장이 될 수 잇는 모든 상태들의 집합

Q14. 반복적인 상태를 수행 할 수 있도록 ?를 사용<br>
A14. ? = 해시테이블 이용

Q15. 문제 해결 성능 척도<br>
A15.
* 완전성? - 해결책 탐색에 대해 발견을 완전히 보장 하는가?
* 최적성? - 최적으로 해결책을 찾아주는가?
* 시간복잡도 - 시간이 얼마나 걸리는가?
* 공간복잡도 - 메모리는 얼마나 사용되는가?

Q16. 시간 과 공간은 뭐로?<br>
A16. 시간은 탐색동안 생성되는 노드의 갯수로 판가름, 공간은 메모리에 저장되는 노드의 갯수로
